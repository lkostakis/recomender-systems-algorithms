{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file in 2.281 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cicPsia8Wj-DNRkmLbD_xg</td>\n",
       "      <td>Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xVXyrTWbG8U3szze-aA7eg</td>\n",
       "      <td>Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e-tRKAC-q40SqQfAOwYa-A</td>\n",
       "      <td>Beauty &amp; Spas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C9keC4mWuXdl2mYFHZXudQ</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PFS9kf3U-ZCvpqay3AaNnQ</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id     categories\n",
       "0  cicPsia8Wj-DNRkmLbD_xg           Bars\n",
       "1  xVXyrTWbG8U3szze-aA7eg           Bars\n",
       "2  e-tRKAC-q40SqQfAOwYa-A  Beauty & Spas\n",
       "3  C9keC4mWuXdl2mYFHZXudQ       Shopping\n",
       "4  PFS9kf3U-ZCvpqay3AaNnQ       Shopping"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2991 businesses in df_buisness\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time \n",
    "\n",
    "dataset_path = '../data-mining-3/' # Change this path to match your local dataset folder path\n",
    "\n",
    "business_filename = 'yelp_academic_dataset_business.json'\n",
    "review_filename = 'yelp_academic_dataset_review.json'\n",
    "\n",
    "# Reading business file\n",
    "start = time.time()\n",
    "\n",
    "list_business = []\n",
    "categories_order = ['Beauty & Spas', 'Shopping', 'Bars']\n",
    "\n",
    "with open(dataset_path + business_filename, 'r', encoding=\"utf8\") as buisness_file:\n",
    "    for line in buisness_file:\n",
    "        json_dict = json.loads(line)\n",
    "        if  json_dict['city'] == 'Toronto' and \\\n",
    "            json_dict['review_count'] >= 10 and \\\n",
    "            json_dict['categories'] is not None: # and \\\n",
    "            #any(word in json_dict['categories'] for word in categories_order):\n",
    "                cat = [x.strip(\" \") for x in json_dict['categories'].split(\",\")]\n",
    "                if \"Beauty & Spas\" in cat:\n",
    "                    temp_cat = \"Beauty & Spas\"\n",
    "                    list_business.append([json_dict['business_id'], temp_cat])\n",
    "                elif \"Shopping\" in cat:\n",
    "                    temp_cat = \"Shopping\"\n",
    "                    list_business.append([json_dict['business_id'], temp_cat])\n",
    "                elif \"Bars\" in cat:\n",
    "                    temp_cat = \"Bars\"\n",
    "                    list_business.append([json_dict['business_id'], temp_cat]) \n",
    "                # The following line makes sure that every buisness categoy is\n",
    "                # set to one of the categories_order list in that specific order.\n",
    "                # temp_cat = [cat for cat in categories_order if cat in json_dict['categories']][0]\n",
    "                # list_business.append([json_dict['business_id'], temp_cat])\n",
    "\n",
    "stop = time.time()\n",
    "print(\"Read file in {:.3f} seconds\".format(stop-start))\n",
    "\n",
    "df_buisness = pd.DataFrame(list_business, columns=['business_id', 'categories'])\n",
    "display(df_buisness.head())\n",
    "print('{} businesses in df_buisness'.format(df_buisness['business_id'].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cicPsia8Wj-DNRkmLbD_xg', 'xVXyrTWbG8U3szze-aA7eg',\n",
       "       'e-tRKAC-q40SqQfAOwYa-A', ..., 'wjqOdj0XJUDOOtU9LjRlWQ',\n",
       "       'AqpB2IoLkUupDCuH-hmVdg', '0hudPyuCBlKg79OwKBw-eQ'], dtype='<U22')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting unique buisness ids\n",
    "np_businesses = np.array(list_business)\n",
    "np_businesses_ids = np_businesses[:,0]\n",
    "np_businesses_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file in 5.457 mins\n"
     ]
    }
   ],
   "source": [
    "def find_buisness_index(business_id):\n",
    "    index = np.where(np_businesses_ids == business_id)[0]\n",
    "    return index\n",
    "\n",
    "# Reading reveiws file\n",
    "start = time.time()\n",
    "business_reviews = [[] for i in range(int(len(np_businesses_ids)))]\n",
    "\n",
    "with open(dataset_path + review_filename, 'r', encoding=\"utf8\") as reviews_file:\n",
    "    for line in reviews_file:\n",
    "        json_dict = json.loads(line)\n",
    "        index = find_buisness_index(json_dict['business_id'])\n",
    "        if index.size > 0:\n",
    "            if len(business_reviews[index[0]]) == 0:\n",
    "                business_reviews[index[0]] = json_dict['text']\n",
    "            else:\n",
    "                business_reviews[index[0]] += json_dict['text']\n",
    "\n",
    "stop = time.time()\n",
    "print(\"Read file in {:.3f} mins\".format((stop-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews as a single string for each buisness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Consistently good, as the Keg tends to be.\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would give zero stars. I came here with a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A blissful experience! I highly recommended th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're a boy and you want to wear some hot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a country girl, I often find myself missing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>Good tacos in the downtown core are hard to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>This used to be my favourite place. It was alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>Very welcoming place. Great setup and super fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>I can't beleive I am saying this... but I left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>We had pizza and fish &amp; chips. \\nThe pizza was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2991 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviews as a single string for each buisness\n",
       "0     Consistently good, as the Keg tends to be.\\n\\n...\n",
       "1     I would give zero stars. I came here with a gr...\n",
       "2     A blissful experience! I highly recommended th...\n",
       "3     If you're a boy and you want to wear some hot ...\n",
       "4     As a country girl, I often find myself missing...\n",
       "...                                                 ...\n",
       "2986  Good tacos in the downtown core are hard to co...\n",
       "2987  This used to be my favourite place. It was alw...\n",
       "2988  Very welcoming place. Great setup and super fr...\n",
       "2989  I can't beleive I am saying this... but I left...\n",
       "2990  We had pizza and fish & chips. \\nThe pizza was...\n",
       "\n",
       "[2991 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business_reviews = pd.DataFrame(business_reviews, columns=['reviews as a single string for each buisness'])\n",
    "df_business_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# Load custom stopwords \n",
    "# source: https://github.com/kavgan/nlp-in-practice/blob/master/tf-idf/resources/stopwords.txt\n",
    "with open('stopwords.txt', 'r') as text_file:\n",
    "    lines = text_file.read().split('\\n')\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(lines)\n",
    "\n",
    "# Allowing words that are alpharithmetics more than 2 chars, excluding\n",
    "# common words that exist in more than max_df of docs and rare words that\n",
    "# exist in less than min_df of docs.\n",
    "tfidf = TfidfVectorizer(min_df=0.25,\n",
    "                        max_df=0.85,\n",
    "                        max_features=8000,\n",
    "                        token_pattern=r'(?u)\\b[A-Za-z][A-Za-z]+\\b',\n",
    "                        lowercase=True,\n",
    "                        stop_words=stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True values table: Îœatching categories to numbers\n",
    "true_labels = np_businesses[:,1]\n",
    "for i in range(len(true_labels)):\n",
    "    if true_labels[i]=='Bars':\n",
    "        true_labels[i]=0\n",
    "    if true_labels[i]=='Beauty & Spas':\n",
    "        true_labels[i]=1\n",
    "    if true_labels[i]=='Shopping':\n",
    "        true_labels[i]=2\n",
    "    \n",
    "true_labels = [int(i) for i in true_labels] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392\n",
      "599\n",
      "2393\n",
      "598\n",
      "2393\n",
      "598\n",
      "2393\n",
      "598\n",
      "2393\n",
      "598\n"
     ]
    }
   ],
   "source": [
    "input_train = []\n",
    "input_test = []\n",
    "output_train = []\n",
    "output_test = []\n",
    "\n",
    "for train_index, test_index in kf.split(business_reviews):\n",
    "    cc = 0\n",
    "    for i in range(len(train_index)):\n",
    "        cc+=1\n",
    "        input_train.append(business_reviews[train_index[i]])\n",
    "        output_train.append(np.asarray(true_labels)[train_index[i]])\n",
    "    print(cc)\n",
    "    cc=0\n",
    "    for i in range(len(test_index)):\n",
    "        cc+=1\n",
    "        input_test.append(business_reviews[test_index[i]])\n",
    "        output_test.append(np.asarray(true_labels)[test_index[i]])\n",
    "    print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_train =  [input_train[0:2392], input_train[2392:4785], input_train[4785:7178],\n",
    "               input_train[7178:9571], input_train[9571:]]\n",
    "output_train = [output_train[0:2392], output_train[2392:4785], output_train[4785:7178],\n",
    "                output_train[7178:9571], output_train[9571:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_test = [input_test[0:599], input_test[599:1197], input_test[1197:1795],\n",
    "              input_test[1795:2393], input_test[2393:]]\n",
    "output_test =[output_test[0:599], output_test[599:1197], output_test[1197:1795],\n",
    "              output_test[1795:2393], output_test[2393:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix is\n",
      "[[249.   0.   1.]\n",
      " [  1. 158.   5.]\n",
      " [ 15.   4. 161.]]\n",
      "Average accuracy is 0.951521208703469\n",
      "Average F1 Score is 0.9510799990341846\n",
      "Average Precision Score is 0.9522482359825408\n",
      "Average recall score is 0.951521208703469\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0 \n",
    "average_precision = 0\n",
    "average_recall = 0\n",
    "average_conf_matrix = np.zeros([3,3])\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    X = tfidf.fit_transform(input_train[i])\n",
    "    X_test = tfidf.transform(input_test[i])\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, p=2) #Euclidean distance\n",
    "    classifier = classifier.fit(X, output_train[i])\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    average_conf_matrix += confusion_matrix(output_test[i], y_pred)\n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i], y_pred, average='weighted')\n",
    "    average_precision += precision_score(output_test[i], y_pred, average='weighted')\n",
    "    average_recall += recall_score(output_test[i], y_pred, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Average Confusion Matrix is\")\n",
    "print(average_conf_matrix//5)\n",
    "print(\"Average accuracy is\", average_acc/5)\n",
    "print(\"Average F1 Score is\", average_f1/5)\n",
    "print(\"Average Precision Score is\", average_precision/5)\n",
    "print(\"Average recall score is\", average_recall/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix is\n",
      "[[250.   0.   1.]\n",
      " [  1. 158.   5.]\n",
      " [ 10.   1. 169.]]\n",
      "Average accuracy is 0.965898012853083\n",
      "Average F1 Score is 0.9657588461257763\n",
      "Average Precision Score is 0.9663390094489145\n",
      "Average recall score is 0.965898012853083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0 \n",
    "average_precision = 0\n",
    "average_recall = 0\n",
    "average_conf_matrix = np.zeros([3,3])\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    X = tfidf.fit_transform(input_train[i])\n",
    "    X_test = tfidf.transform(input_test[i])\n",
    "    svm = SVC(kernel='rbf', gamma='scale') # Gaussian Kernel\n",
    "    svm = svm.fit(X, output_train[i])\n",
    "    \n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    average_conf_matrix += confusion_matrix(output_test[i], y_pred)\n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i], y_pred, average='weighted')\n",
    "    average_precision += precision_score(output_test[i], y_pred, average='weighted', zero_division=0)\n",
    "    average_recall += recall_score(output_test[i], y_pred, average='weighted')\n",
    "    \n",
    "print(\"Average Confusion Matrix is\")\n",
    "print(average_conf_matrix//5)\n",
    "print(\"Average accuracy is\", average_acc/5)\n",
    "print(\"Average F1 Score is\", average_f1/5)\n",
    "print(\"Average Precision Score is\", average_precision/5)\n",
    "print(\"Average recall score is\", average_recall/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix is\n",
      "[[250.   0.   1.]\n",
      " [  1. 157.   6.]\n",
      " [ 11.   2. 167.]]\n",
      "Average accuracy is 0.9615513034544755\n",
      "Average F1 Score is 0.9613588145903711\n",
      "Average Precision Score is 0.962049074849269\n",
      "Average recall score is 0.9615513034544755\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0 \n",
    "average_precision = 0\n",
    "average_recall = 0\n",
    "average_conf_matrix = np.zeros([3,3])\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    X = tfidf.fit_transform(input_train[i])\n",
    "    X_test = tfidf.transform(input_test[i])\n",
    "    svm = SVC(kernel='linear', gamma='scale') # Linear Kernel\n",
    "    svm = svm.fit(X, output_train[i])\n",
    "    \n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    average_conf_matrix += confusion_matrix(output_test[i], y_pred)\n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i], y_pred, average='weighted')\n",
    "    average_precision += precision_score(output_test[i], y_pred, average='weighted', zero_division=0)\n",
    "    average_recall += recall_score(output_test[i], y_pred, average='weighted')\n",
    "\n",
    "print(\"Average Confusion Matrix is\")\n",
    "print(average_conf_matrix//5)\n",
    "print(\"Average accuracy is\", average_acc/5)\n",
    "print(\"Average F1 Score is\", average_f1/5)\n",
    "print(\"Average Precision Score is\", average_precision/5)\n",
    "print(\"Average recall score is\", average_recall/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix is\n",
      "[[246.   0.   4.]\n",
      " [  1. 155.   8.]\n",
      " [ 11.   7. 162.]]\n",
      "Average accuracy is 0.9434972445714986\n",
      "Average F1 Score is 0.9432066148406119\n",
      "Average Precision Score is 0.9434421159913817\n",
      "Average recall score is 0.9434972445714986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0 \n",
    "average_precision = 0\n",
    "average_recall = 0\n",
    "average_conf_matrix = np.zeros([3,3])\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    X = tfidf.fit_transform(input_train[i])\n",
    "    X_test = tfidf.transform(input_test[i])\n",
    "    nb = GaussianNB()\n",
    "    nb = nb.fit(X.todense(), output_train[i])\n",
    "    \n",
    "    y_pred = nb.predict(X_test.todense())\n",
    "    \n",
    "    average_conf_matrix += confusion_matrix(output_test[i], y_pred)\n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i], y_pred, average='weighted')\n",
    "    average_precision += precision_score(output_test[i], y_pred, average='weighted', zero_division=0)\n",
    "    average_recall += recall_score(output_test[i], y_pred, average='weighted')\n",
    "\n",
    "print(\"Average Confusion Matrix is\")\n",
    "print(average_conf_matrix//5)\n",
    "print(\"Average accuracy is\", average_acc/5)\n",
    "print(\"Average F1 Score is\", average_f1/5)\n",
    "print(\"Average Precision Score is\", average_precision/5)\n",
    "print(\"Average recall score is\", average_recall/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use LBFGS algorithm for optimization or newton-cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Confusion Matrix is\n",
      "[[248.   0.   2.]\n",
      " [  1. 157.   6.]\n",
      " [ 11.   2. 167.]]\n",
      "Average accuracy is 0.9592101663307295\n",
      "Average F1 Score is 0.9590497032847048\n",
      "Average Precision Score is 0.9596032357353262\n",
      "Average recall score is 0.9592101663307295\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0 \n",
    "average_precision = 0\n",
    "average_recall = 0\n",
    "average_conf_matrix = np.zeros([3,3])\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    X = tfidf.fit_transform(input_train[i])\n",
    "    X_test = tfidf.transform(input_test[i])\n",
    "    linear_clf = linear_model.LogisticRegression(solver='newton-cg')\n",
    "    linear_clf.fit(X, output_train[i])\n",
    "    \n",
    "    y_pred = linear_clf.predict(X_test)\n",
    "    \n",
    "    average_conf_matrix += confusion_matrix(output_test[i], y_pred)\n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i], y_pred, average='weighted')\n",
    "    average_precision += precision_score(output_test[i], y_pred, average='weighted', zero_division=0)\n",
    "    average_recall += recall_score(output_test[i], y_pred, average='weighted')\n",
    "\n",
    "print(\"Average Confusion Matrix is\")\n",
    "print(average_conf_matrix//5)\n",
    "print(\"Average accuracy is\", average_acc/5)\n",
    "print(\"Average F1 Score is\", average_f1/5)\n",
    "print(\"Average Precision Score is\", average_precision/5)\n",
    "print(\"Average recall score is\", average_recall/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0 \n",
    "average_precision = 0\n",
    "average_recall = 0\n",
    "average_conf_matrix = np.zeros([3,3])\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    X = tfidf.fit_transform(input_train[i])\n",
    "    X_test = tfidf.transform(input_test[i])\n",
    "    decision_tree = tree.DecisionTreeClassifier()\n",
    "    decision_tree = decision_tree.fit(X, output_train[i])\n",
    "\n",
    "    y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "    average_conf_matrix += confusion_matrix(output_test[i], y_pred)\n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i], y_pred, average='weighted')\n",
    "    average_precision += precision_score(output_test[i], y_pred, average='weighted', zero_division=0)\n",
    "    average_recall += recall_score(output_test[i], y_pred, average='weighted')\n",
    "\n",
    "print(\"Average Confusion Matrix is\")\n",
    "print(average_conf_matrix//5)\n",
    "print(\"Average accuracy is\", average_acc/5)\n",
    "print(\"Average F1 Score is\", average_f1/5)\n",
    "print(\"Average Precision Score is\", average_precision/5)\n",
    "print(\"Average recall score is\", average_recall/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "It might be a coincidence.\n",
    "\n",
    "If we have to say something about it, then it indicates that sensitivity (a.k.a. recall, or TPR) is equal to specificity (a.k.a. selectivity, or TNR), and thus they are also equal to accuracy. TP / P = TN / N = (TP+TN) / (P+N), where P = TP+FN, N = TN+FP.\n",
    "\n",
    "This means your model is somehow \"balanced\", that is, its ability to correctly classify positive samples is same as its ability to correctly classify negative samples.\n",
    "\n",
    "However, the importance of sensitivity and specificity may vary from case to case, so being \"balanced\" is not necessarily good.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As OP has mentioned, this is just a coincidence. It's highly likely that number of instances in each class is balanced. Recall = TP/P and Acc = (TP + TN)/(P+N), so in your case TP/P = TN/N. This can happen, and is more likely to happen when |P| = |N|\n",
    "\n",
    "Try following: Print upto 7-8 places of decimal and you may see some difference.\n",
    "\n",
    "Second try to imbalance the problem. Like set positive class as just 20% of total and let rest be 80%, you should definitely see the difference.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As OP has mentioned, this is just a coincidence. It's highly likely that number of instances in each class is balanced. Recall = TP/P and Acc = (TP + TN)/(P+N), so in your case TP/P = TN/N. This can happen, and is more likely to happen when |P| = |N|\n",
    "\n",
    "Try following: Print upto 7-8 places of decimal and you may see some difference.\n",
    "\n",
    "Second try to imbalance the problem. Like set positive class as just 20% of total and let rest be 80%, you should definitely see the difference.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Î•Î¡Î©Î¤Î—ÎœÎ‘ Î’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "filepath = '/home/left/github/data-mining-3/GoogleNews-vectors-negative300.bin'\n",
    "g_model = gensim.models.KeyedVectors.load_word2vec_format(filepath, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-9958a3d4c933>:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if w in g_model.wv:\n"
     ]
    }
   ],
   "source": [
    "X_news_train_gmodel = []\n",
    "for x in business_reviews[0]:\n",
    "    vx = np.zeros(300)\n",
    "    length = 0\n",
    "    for w in x: \n",
    "        if w in g_model.wv:\n",
    "            length += 1\n",
    "            vx += g_model[w]\n",
    "    if length != 0: vx /= length\n",
    "    X_news_train_gmodel.append(vx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-8c985c83a0ef>:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if (w not in g_model.wv): continue\n",
      "<ipython-input-19-8c985c83a0ef>:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  vx += g_model.wv[w]\n"
     ]
    }
   ],
   "source": [
    "X_news_test_gmodel = []\n",
    "for x in business_reviews[0]:\n",
    "    vx = np.zeros(300)\n",
    "    length = 0\n",
    "    for w in x: \n",
    "        if (w not in g_model.wv): continue\n",
    "        length += 1\n",
    "        vx += g_model.wv[w]\n",
    "    if length != 0: vx /= length\n",
    "    X_news_test_gmodel.append(vx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [70030, 2991]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8774e69d4788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlinear_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlinear_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_news_train_gmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/data/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[1;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[0;32m~/anaconda3/envs/data/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [70030, 2991]"
     ]
    }
   ],
   "source": [
    "linear_clf = linear_model.LogisticRegression(solver='newton-cg')\n",
    "linear_clf.fit(X_news_train_gmodel, np.array(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
