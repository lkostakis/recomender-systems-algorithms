{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file in 2.357 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cicPsia8Wj-DNRkmLbD_xg</td>\n",
       "      <td>Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xVXyrTWbG8U3szze-aA7eg</td>\n",
       "      <td>Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e-tRKAC-q40SqQfAOwYa-A</td>\n",
       "      <td>Beauty &amp; Spas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C9keC4mWuXdl2mYFHZXudQ</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PFS9kf3U-ZCvpqay3AaNnQ</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id     categories\n",
       "0  cicPsia8Wj-DNRkmLbD_xg           Bars\n",
       "1  xVXyrTWbG8U3szze-aA7eg           Bars\n",
       "2  e-tRKAC-q40SqQfAOwYa-A  Beauty & Spas\n",
       "3  C9keC4mWuXdl2mYFHZXudQ       Shopping\n",
       "4  PFS9kf3U-ZCvpqay3AaNnQ       Shopping"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2991 businesses in df_buisness\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time \n",
    "\n",
    "dataset_path = '../data-mining-3/' # Change this path to match your local dataset folder path\n",
    "\n",
    "business_filename = 'yelp_academic_dataset_business.json'\n",
    "review_filename = 'yelp_academic_dataset_review.json'\n",
    "\n",
    "# Reading business file\n",
    "start = time.time()\n",
    "\n",
    "list_business = []\n",
    "categories_order = ['Beauty & Spas', 'Shopping', 'Bars']\n",
    "\n",
    "with open(dataset_path + business_filename, 'r', encoding=\"utf8\") as buisness_file:\n",
    "    for line in buisness_file:\n",
    "        json_dict = json.loads(line)\n",
    "        if  json_dict['city'] == 'Toronto' and \\\n",
    "            json_dict['review_count'] >= 10 and \\\n",
    "            json_dict['categories'] is not None: # and \\\n",
    "            #any(word in json_dict['categories'] for word in categories_order):\n",
    "                cat = [x.strip(\" \") for x in json_dict['categories'].split(\",\")]\n",
    "                if \"Beauty & Spas\" in cat:\n",
    "                    temp_cat = \"Beauty & Spas\"\n",
    "                    list_business.append([json_dict['business_id'], temp_cat])\n",
    "                elif \"Shopping\" in cat:\n",
    "                    temp_cat = \"Shopping\"\n",
    "                    list_business.append([json_dict['business_id'], temp_cat])\n",
    "                elif \"Bars\" in cat:\n",
    "                    temp_cat = \"Bars\"\n",
    "                    list_business.append([json_dict['business_id'], temp_cat]) \n",
    "                # The following line makes sure that every buisness categoy is\n",
    "                # set to one of the categories_order list in that specific order.\n",
    "                # temp_cat = [cat for cat in categories_order if cat in json_dict['categories']][0]\n",
    "                # list_business.append([json_dict['business_id'], temp_cat])\n",
    "\n",
    "stop = time.time()\n",
    "print(\"Read file in {:.3f} seconds\".format(stop-start))\n",
    "\n",
    "df_buisness = pd.DataFrame(list_business, columns=['business_id', 'categories'])\n",
    "display(df_buisness.head())\n",
    "print('{} businesses in df_buisness'.format(df_buisness['business_id'].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cicPsia8Wj-DNRkmLbD_xg', 'xVXyrTWbG8U3szze-aA7eg',\n",
       "       'e-tRKAC-q40SqQfAOwYa-A', ..., 'wjqOdj0XJUDOOtU9LjRlWQ',\n",
       "       'AqpB2IoLkUupDCuH-hmVdg', '0hudPyuCBlKg79OwKBw-eQ'], dtype='<U22')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting unique buisness ids\n",
    "np_businesses = np.array(list_business)\n",
    "np_businesses_ids = np_businesses[:,0]\n",
    "np_businesses_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read file in 5.061 mins\n"
     ]
    }
   ],
   "source": [
    "def find_buisness_index(business_id):\n",
    "    index = np.where(np_businesses_ids == business_id)[0]\n",
    "    return index\n",
    "\n",
    "# Reading reveiws file\n",
    "start = time.time()\n",
    "business_reviews = [[] for i in range(int(len(np_businesses_ids)))]\n",
    "\n",
    "with open(dataset_path + review_filename, 'r', encoding=\"utf8\") as reviews_file:\n",
    "    for line in reviews_file:\n",
    "        json_dict = json.loads(line)\n",
    "        index = find_buisness_index(json_dict['business_id'])\n",
    "        if index.size > 0:\n",
    "            if len(business_reviews[index[0]]) == 0:\n",
    "                business_reviews[index[0]] = json_dict['text']\n",
    "            else:\n",
    "                business_reviews[index[0]] += json_dict['text']\n",
    "\n",
    "stop = time.time()\n",
    "print(\"Read file in {:.3f} mins\".format((stop-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews as a single string for each buisness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Consistently good, as the Keg tends to be.\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I would give zero stars. I came here with a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A blissful experience! I highly recommended th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're a boy and you want to wear some hot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a country girl, I often find myself missing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>Good tacos in the downtown core are hard to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>This used to be my favourite place. It was alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>Very welcoming place. Great setup and super fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>I can't beleive I am saying this... but I left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>We had pizza and fish &amp; chips. \\nThe pizza was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2991 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviews as a single string for each buisness\n",
       "0     Consistently good, as the Keg tends to be.\\n\\n...\n",
       "1     I would give zero stars. I came here with a gr...\n",
       "2     A blissful experience! I highly recommended th...\n",
       "3     If you're a boy and you want to wear some hot ...\n",
       "4     As a country girl, I often find myself missing...\n",
       "...                                                 ...\n",
       "2986  Good tacos in the downtown core are hard to co...\n",
       "2987  This used to be my favourite place. It was alw...\n",
       "2988  Very welcoming place. Great setup and super fr...\n",
       "2989  I can't beleive I am saying this... but I left...\n",
       "2990  We had pizza and fish & chips. \\nThe pizza was...\n",
       "\n",
       "[2991 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_business_reviews = pd.DataFrame(business_reviews, columns=['reviews as a single string for each buisness'])\n",
    "df_business_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/left/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# Load custom stopwords \n",
    "# source: https://github.com/kavgan/nlp-in-practice/blob/master/tf-idf/resources/stopwords.txt\n",
    "with open('stopwords.txt', 'r') as text_file:\n",
    "    lines = text_file.read().split('\\n')\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(lines)\n",
    "\n",
    "# Allowing words that are alpharithmetics more than 2 chars, excluding\n",
    "# common words that exist in more than max_df of docs and rare words that\n",
    "# exist in less than min_df of docs.\n",
    "tfidf = TfidfVectorizer(min_df=0.25,\n",
    "                        max_df=0.85,\n",
    "                        max_features=8000,\n",
    "                        token_pattern=r'(?u)\\b[A-Za-z][A-Za-z]+\\b',\n",
    "                        lowercase=True,\n",
    "                        stop_words=stop_words)\n",
    "\n",
    "document_term_matrix = tfidf.fit_transform(business_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of words included in the features:\n",
      "['sort', 'maybe', 'carry', 'middle', 'wife', 'gave', 'normally', 'complete', 'terrible', 'makes', 'delicious', 'customer', 'option', 'filled', 'late', 'bought', 'cozy', 'opened', 'tons', 'overly', 'attention', 'beers', 'share', 'drop', 'gem', 'ice', 'fix', 'colour', 'bright', 'pictures']\n",
      "\n",
      "\n",
      "Sample of effective stop words list.:\n",
      "['over', 'without', 'already', 'g', 'certainer', 'aer', 'cer', 'overallest', 'herein', 'interest', 'variousest', 'forbye', 'lest', 'unto', 'top', 'during', 'forer', 'somewhat', 'exes', 'h2', 'oftenest', 'were', 'around', 'different', 'their', 'lt', 'whereafter', 'where', 'provide', 'thyself']\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "samples_num = 30\n",
    "print('Sample of words included in the features:\\n{}\\n\\n'.format(random.sample(tfidf.get_feature_names(), samples_num)))\n",
    "print('Sample of effective stop words list.:\\n{}'.format(random.sample(tfidf.get_stop_words(), samples_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True values table: Μatching categories to numbers\n",
    "true_labels = np_businesses[:,1]\n",
    "for i in range(len(true_labels)):\n",
    "    if true_labels[i]=='Bars':\n",
    "        true_labels[i]=0\n",
    "    if true_labels[i]=='Beauty & Spas':\n",
    "        true_labels[i]=1\n",
    "    if true_labels[i]=='Shopping':\n",
    "        true_labels[i]=2\n",
    "    \n",
    "true_labels = [int(i) for i in true_labels] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 5,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(document_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = []\n",
    "input_test = []\n",
    "output_train = []\n",
    "output_test = []\n",
    "\n",
    "for train_index, test_index in kf.split(document_term_matrix):\n",
    "    input_train.append(document_term_matrix[train_index])\n",
    "    input_test.append(document_term_matrix[test_index])\n",
    "    output_train.append(np.asarray(true_labels)[train_index])\n",
    "    output_test.append(np.asarray(true_labels)[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9478428372817573\n",
      "The F1 Score is [0.96009826 0.96367876 0.91416484]\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0 \n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors = 10, p=2) #Euclidean distance\n",
    "    classifier = classifier.fit(input_train[i], output_train[i])\n",
    "    \n",
    "    y_pred = classifier.predict(input_test[i])\n",
    "    \n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i], y_pred, average=None)\n",
    "\n",
    "print(\"The accuracy is\", average_acc/5)\n",
    "print(\"The F1 Score is\", average_f1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
